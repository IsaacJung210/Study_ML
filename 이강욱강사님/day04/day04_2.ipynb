{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6f809d7-47b1-4231-9cd1-160ba3679896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6ea5c9a-336a-4192-81e0-c71a4a8ec4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "084cf028-70b7-4c95-ae70-4944d5b8768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Activation function\n",
    "# sigmoid\n",
    "# softmax\n",
    "# relu\n",
    "\n",
    "## 2. Loss function\n",
    "# mse\n",
    "# cross_entropy_error\n",
    "\n",
    "\n",
    "# 3. differ function\n",
    "# numerical_gradient  Why? 수치미분, (fxh - fx)/h \n",
    "\n",
    "# Layer - One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cffe663-11ee-4b99-91da-72123353104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Activation\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.where(x <= 0, 0,x)\n",
    "\n",
    "def softmax(x):\n",
    "    x = x - np.max(x,axis=1).reshape(-1,1)\n",
    "    return np.exp(x)/np.sum(np.exp(x),axis=1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfbaf797-c657-4150-a16c-d6c9207f2790",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 loss Function\n",
    "def cross_entropy_error(y,t):\n",
    "    delta = 1e-5\n",
    "    return -np.sum(t*np.log(y+delta))/y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "528090bb-37f7-4e06-b051-9ca81f64f468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 differ function\n",
    "def numerical_gradient(f,x):\n",
    "    h = 1e-4\n",
    "    grads = np.zeros_like(x)\n",
    "    if x.ndim == 2:\n",
    "        for i in range(x.shape[0]):\n",
    "            for j in range(x.shape[1]):\n",
    "                fx = f(x[i,j])\n",
    "                tmp_val = x[i,j]\n",
    "                x[i,j] = tmp_val + h\n",
    "                fxh = f(x[i,j])\n",
    "                grads[i,j] = (fxh - fx)/h\n",
    "                x[i,j] = tmp_val\n",
    "    else:\n",
    "        for i in range(x.size):\n",
    "            fx = f(x[i])\n",
    "            tmp_val = x[i]\n",
    "            x[i] = tmp_val + h\n",
    "            fxh = f(x[i])\n",
    "            grads[i] = (fxh - fx)/h\n",
    "            x[i] = tmp_val\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50a68b3b-25ce-49d8-93d1-4953632a0b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_wine()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57f44c39-a753-4bb5-8e5f-aebe10009588",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = load_wine()['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54140431-8134-428a-a309-35b01a94d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.zeros((y.size,np.unique(y).size))\n",
    "for i in range(t.shape[0]):\n",
    "    t[i,y[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b39f86c5-bac1-47a7-a2dd-7ddeab026c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x,w):\n",
    "    return softmax(np.dot(x,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3f23d82c-7d92-4c86-8808-7a019648b93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.randn(13,3)\n",
    "pred = predict(X,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36108b72-58cb-479c-94ce-fc104627ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda W: cross_entropy_error(pred,t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aad1a6ae-2581-4837-b22e-8eed05643c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dW = numerical_gradient(f,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7d8d747a-da9d-4800-8f70-9bbc186b1d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "dW = numerical_gradient(f,w)\n",
    "w = w - lr*dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c331d5bb-f8bc-46dc-a6d7-7a2905e3ae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 network 설계\n",
    "#2 predict = X*network\n",
    "#3 predict result vs true value 오차함수 생성\n",
    "#4 함수를 미분\n",
    "#5 미분값을 lr와 곱해서 빼준후 update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1892cf4f-598f-46f8-8c8f-493e3a5158a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneLayer:\n",
    "    def __init__(self,input_size,output_size):\n",
    "        self.W = {}\n",
    "        self.W['W1'] = np.random.randn(input_size,output_size)\n",
    "        self.W['b'] = np.random.randn(output_size)\n",
    "    \n",
    "    def predict(self,x):\n",
    "        W1, b = self.W['W1'], self.W['b']\n",
    "        pred = softmax(np.dot(x,W1) + b)\n",
    "        return pred\n",
    "    \n",
    "    def loss(self,x,t):\n",
    "        y = self.predict(x)\n",
    "        return cross_entropy_error(y,t)\n",
    "    \n",
    "    def numerical_gradient(self,x,t):\n",
    "        y = self.predict(x)\n",
    "        f = lambda W: cross_entropy_error(y,t)\n",
    "        grad = {}\n",
    "        grad['W1'] = numerical_gradient(f,self.W['W1'])\n",
    "        grad['b'] = numerical_gradient(f, self.W['b'])\n",
    "        \n",
    "        return grad\n",
    "    \n",
    "    def accuracy(self,x,t):\n",
    "        y = self.predict(x)\n",
    "        acc = np.sum(np.argmax(y,axis=1) == np.argmax(t,axis=1))/y.shape[0]\n",
    "        return acc\n",
    "    \n",
    "    def fit(self,x,t,epochs=1000,lr=1e-3,verbos=1):\n",
    "        for epoch in range(epochs):\n",
    "            self.W['W1'] = self.W['W1'] - lr*self.numerical_gradient(x,t)['W1']\n",
    "            self.W['b'] -= lr*self.numerical_gradient(x,t)['b']\n",
    "            if verbos == 1:\n",
    "                print(\"=========== loss \",self.loss(x,t), \"======== acc \",self.accuracy(x,t))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d1856a4f-597e-442d-a1ba-ec824f8dbdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X.shape[1]\n",
    "output_size = t.shape[1]\n",
    "model = OneLayer(input_size=input_size, output_size=output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "35236b20-7d1d-4a06-835d-85cb1f685b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,t,verbos=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c072fc0-d5fc-4159-8fd8-93577d38474c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
